{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fda922",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b4a31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch.nn.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3808/768220717.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch.nn.data'"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4dd35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacyNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading spacy-3.5.2-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\itsal\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: typing-extensions, colorama, catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 colorama-0.4.6 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 smart-open-6.3.0 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.7.0 typing-extensions-4.5.0 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc68e6",
   "metadata": {},
   "source": [
    "## Aladdin Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ebf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, freq_threshold):\n",
    "        self.itos = {0:\"<PAD>\",1:\"<SOS>\",2:\"<EOS>\",3:\"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\":0,\"<SOS>\":1,\"<EOS>\":2,\"<UNK>\":3}\n",
    "        self.freq_threshold = freq_threshold\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenize_eng(text):\n",
    "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
    "    \n",
    "    def build_vocabulary\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aksharantar(Dataset):\n",
    "    def __init__(self, root_dir, data_file, transform=None, freq_threshold=5):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = pd.read_csv(data_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get the latin and devangari script\n",
    "        self.latin = self.df.iloc[:,0]\n",
    "        self.hindi = self.df.iloc[:,1]\n",
    "        \n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab = Vocabulary(freq_threshold)\n",
    "        self.vocab.build_vocabulary(self.hindi.tolist())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        latin = self.latin[index]\n",
    "        hindi = self.hindi[index]\n",
    "        \n",
    "#         if self.transform is not None:\n",
    "#             hindi = self.transform(hindi)\n",
    "        \n",
    "        numericalized_hindi = [self.vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_hindi += self.vocab.numericalize(hindi)\n",
    "        numericalized_hindi.append(self.vocab.stoi[\"<EOS\"])\n",
    "        \n",
    "        numericalized_latin = [self.vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_latin += self.vocab.numericalize(latin)\n",
    "        numericalized_latin.append(self.vocab.stoi[\"<EOS\"])\n",
    "        \n",
    "        return torch.tensor(numericalized_latin), torch.tensor(numericalized_hindi) \n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855833f",
   "metadata": {},
   "source": [
    "## Loading the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0429c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "# Give the path of the downloaded datatset for your model\n",
    "train_path = r\"C:\\Users\\HICLIPS-ASK\\aksharantar_sampled\\hin\\hin_train.csv\"\n",
    "val_path = r\"C:\\Users\\HICLIPS-ASK\\aksharantar_sampled\\hin\\hin_valid.csv\"\n",
    "test_path = r\"C:\\Users\\HICLIPS-ASK\\aksharantar_sampled\\hin\\hin_test.csv\"\n",
    "train_data = pd.read_csv(train_path,header=None)\n",
    "valid_data = pd.read_csv(val_path,header=None)\n",
    "test_data = pd.read_csv(test_path,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3106ff60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shastragaar</td>\n",
       "      <td>शस्त्रागार</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bindhya</td>\n",
       "      <td>बिन्द्या</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kirankant</td>\n",
       "      <td>किरणकांत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yagyopaveet</td>\n",
       "      <td>यज्ञोपवीत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ratania</td>\n",
       "      <td>रटानिया</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51195</th>\n",
       "      <td>toned</td>\n",
       "      <td>टोंड</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51196</th>\n",
       "      <td>mutanaazaa</td>\n",
       "      <td>मुतनाज़ा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51197</th>\n",
       "      <td>asahmaton</td>\n",
       "      <td>असहमतों</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51198</th>\n",
       "      <td>sulgaayin</td>\n",
       "      <td>सुलगायीं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51199</th>\n",
       "      <td>anchuthengu</td>\n",
       "      <td>अंचुतेंगु</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1\n",
       "0      shastragaar  शस्त्रागार\n",
       "1          bindhya    बिन्द्या\n",
       "2        kirankant    किरणकांत\n",
       "3      yagyopaveet   यज्ञोपवीत\n",
       "4          ratania     रटानिया\n",
       "...            ...         ...\n",
       "51195        toned        टोंड\n",
       "51196   mutanaazaa    मुतनाज़ा\n",
       "51197    asahmaton     असहमतों\n",
       "51198    sulgaayin    सुलगायीं\n",
       "51199  anchuthengu   अंचुतेंगु\n",
       "\n",
       "[51200 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3a5a9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\"\n",
    "    This function will convert our 'data' into input(x) and labels(y)\n",
    "    Latin word taken as x for the modelling purpose\n",
    "    devanagri word taken as y for the modelling purpose\n",
    "    \n",
    "    \"\"\"\n",
    "    x_data = data.iloc[:,0].values\n",
    "    y_data = data.iloc[:,1].values\n",
    "    \n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d19dd5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_data(train_data)\n",
    "x_valid, y_valid = prepare_data(valid_data)\n",
    "x_test, y_test = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "17d8ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter2index_index2letter(alpha_type):\n",
    "    \"\"\"\n",
    "    alpha_type: it takes 'english' or 'hindi' value\n",
    "    This function will create dictionaies of character:index(key:value) for both the language scripts\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if alpha_type == 'english':\n",
    "        alphabet_eng = 'abcdefghijklmnopqrstuvwxyz'\n",
    "        letter2index_eng = {}\n",
    "        letter2index_eng['-sos-'] = 0\n",
    "\n",
    "        for ind, c in enumerate(alphabet_eng):\n",
    "            letter2index_eng[c] = ind+1\n",
    "        letter2index_eng['-eos-'] = len(letter2index_eng)\n",
    "        \n",
    "        print(\"__letter to index__\")\n",
    "        print(letter2index_eng)\n",
    "\n",
    "        print(\" \")\n",
    "        print(\"__Index to letter__\")\n",
    "        \n",
    "        ### Index to Letter\n",
    "        index2letter_eng = {}\n",
    "        index2letter_eng[0] = '-sos-'\n",
    "        for ind, c in enumerate(alphabet_eng):\n",
    "            index2letter_eng[ind+1] = c\n",
    "        index2letter_eng[len(index2letter_eng)] = '-eos-'\n",
    "        print(index2letter_eng)\n",
    "        \n",
    "        return letter2index_eng, index2letter_eng\n",
    "        \n",
    "    if alpha_type == 'hindi':\n",
    "        alphabet_hin = [chr(alpha) for alpha in range(2304, 2432)]\n",
    "        letter2index_hin = {}\n",
    "        letter2index_hin['-sos-'] = 0\n",
    "\n",
    "        for ind, c in enumerate(alphabet_hin):\n",
    "            letter2index_hin[c] = ind+1\n",
    "        letter2index_hin['-eos-'] = len(letter2index_hin)\n",
    "        \n",
    "        print(\"__letter to index__\")\n",
    "        print(letter2index_hin)\n",
    "\n",
    "        print(\" \")\n",
    "        print(\"__Index to letter__\")\n",
    "        \n",
    "        ### Index to Letter\n",
    "        index2letter_hin = {}\n",
    "        index2letter_hin[0] = '-sos-'\n",
    "        for ind, c in enumerate(alphabet_hin):\n",
    "            index2letter_hin[ind+1] = c\n",
    "        index2letter_hin[len(index2letter_hin)] = '-eos-'\n",
    "        print(index2letter_hin)\n",
    "        \n",
    "        return letter2index_hin, index2letter_hin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b71f3140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__letter to index__\n",
      "{'-sos-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128, '-eos-': 129}\n",
      " \n",
      "__Index to letter__\n",
      "{0: '-sos-', 1: 'ऀ', 2: 'ँ', 3: 'ं', 4: 'ः', 5: 'ऄ', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ऌ', 14: 'ऍ', 15: 'ऎ', 16: 'ए', 17: 'ऐ', 18: 'ऑ', 19: 'ऒ', 20: 'ओ', 21: 'औ', 22: 'क', 23: 'ख', 24: 'ग', 25: 'घ', 26: 'ङ', 27: 'च', 28: 'छ', 29: 'ज', 30: 'झ', 31: 'ञ', 32: 'ट', 33: 'ठ', 34: 'ड', 35: 'ढ', 36: 'ण', 37: 'त', 38: 'थ', 39: 'द', 40: 'ध', 41: 'न', 42: 'ऩ', 43: 'प', 44: 'फ', 45: 'ब', 46: 'भ', 47: 'म', 48: 'य', 49: 'र', 50: 'ऱ', 51: 'ल', 52: 'ळ', 53: 'ऴ', 54: 'व', 55: 'श', 56: 'ष', 57: 'स', 58: 'ह', 59: 'ऺ', 60: 'ऻ', 61: '़', 62: 'ऽ', 63: 'ा', 64: 'ि', 65: 'ी', 66: 'ु', 67: 'ू', 68: 'ृ', 69: 'ॄ', 70: 'ॅ', 71: 'ॆ', 72: 'े', 73: 'ै', 74: 'ॉ', 75: 'ॊ', 76: 'ो', 77: 'ौ', 78: '्', 79: 'ॎ', 80: 'ॏ', 81: 'ॐ', 82: '॑', 83: '॒', 84: '॓', 85: '॔', 86: 'ॕ', 87: 'ॖ', 88: 'ॗ', 89: 'क़', 90: 'ख़', 91: 'ग़', 92: 'ज़', 93: 'ड़', 94: 'ढ़', 95: 'फ़', 96: 'य़', 97: 'ॠ', 98: 'ॡ', 99: 'ॢ', 100: 'ॣ', 101: '।', 102: '॥', 103: '०', 104: '१', 105: '२', 106: '३', 107: '४', 108: '५', 109: '६', 110: '७', 111: '८', 112: '९', 113: '॰', 114: 'ॱ', 115: 'ॲ', 116: 'ॳ', 117: 'ॴ', 118: 'ॵ', 119: 'ॶ', 120: 'ॷ', 121: 'ॸ', 122: 'ॹ', 123: 'ॺ', 124: 'ॻ', 125: 'ॼ', 126: 'ॽ', 127: 'ॾ', 128: 'ॿ', 129: '-eos-'}\n",
      " \n",
      "__letter to index__\n",
      "{'-sos-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '-eos-': 27}\n",
      " \n",
      "__Index to letter__\n",
      "{0: '-sos-', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '-eos-'}\n"
     ]
    }
   ],
   "source": [
    "letter2index_hin, index2letter_hin = letter2index_index2letter('hindi')\n",
    "print(\" \")\n",
    "letter2index_eng, index2letter_eng = letter2index_index2letter('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1e53b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the words into vector form\n",
    "def word2vector(word, letter2index_dict):\n",
    "    \"\"\"\n",
    "    word: the word which needed to be converted into vector\n",
    "    letter2index_dict: Dictionary created to map the letter to index\n",
    "    This function convert the words into a vector according to the indexing done above.\n",
    "    This will help to make word compatiable for the training\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_vector = []  \n",
    "    encoded_vector.append(letter2index_dict['-sos-'])\n",
    "    for i, w in enumerate(word):\n",
    "        encoded_vector.append(letter2index_dict[w])\n",
    "    \n",
    "    encoded_vector.append(letter2index_dict['-eos-'])\n",
    "    return encoded_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "dd5ef47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 45, 64, 41, 78, 39, 78, 48, 63, 129]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_vector = word2vector(\"बिन्द्या\", letter2index_hin)\n",
    "encoded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c92a3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_words(data, letter2index_dict, word2vector):\n",
    "    \"\"\"\n",
    "    word: the word which needed to be converted into vector.\n",
    "    letter2index_dict: Give the Dictionary created to map the letter to index\n",
    "    for particular language.\n",
    "    word2vector: is a function to convert words into numerical vector\n",
    "    This function will convert first the words into a vecotr form then change the length of all the vectors same as that of \n",
    "    longest lengrh vector. Will return a torch tensor for further processing\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create an empty list to store the encoded representations of words\n",
    "    temp = []  \n",
    "    # Variable to keep track of the maximum length of words\n",
    "    max_length = 0  \n",
    "\n",
    "    # Iterate over each word in x_train along with its index\n",
    "    for i, word in enumerate(data):\n",
    "        rep = word2vector(word, letter2index_dict)  # Encode the word using the function \n",
    "        temp.append(rep)  # Add the encoded representation to temp list\n",
    "\n",
    "        # Check if the current word is longer than the previous maximum length\n",
    "        if max_length < len(rep):\n",
    "            max_length = len(rep)  # Update the maximum length\n",
    "            index = i  # Store the index of the word with maximum length\n",
    "    \n",
    "    #print(f\"the max word size for {data} is: \",max_length)\n",
    "    vectors = []  # Create an empty list to store the final encoded representations of words\n",
    "\n",
    "    # Iterate over each encoded representation in temp\n",
    "    for word in temp:\n",
    "        # Append zeros to the encoded representation if its length is shorter than the maximum length\n",
    "        word = word + ([0] * (max_length - len(word)))\n",
    "        vectors.append(word)  # Add the updated encoded representation to vectors\n",
    "    \n",
    "    # Transforming the list into pytorch tensor\n",
    "    vectors = torch.tensor(vectors, dtype=torch.long, device=device)\n",
    "\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "0c343dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = process_words(x_train, letter2index_eng,word2vector), process_words(y_train, letter2index_hin,word2vector)\n",
    "x_valid, y_valid = process_words(x_valid, letter2index_eng,word2vector), process_words(y_valid, letter2index_hin,word2vector)\n",
    "x_test, y_test = process_words(x_test, letter2index_eng,word2vector), process_words(y_test, letter2index_hin,word2vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b56462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for english\n",
    "# 26 51200\n",
    "# 22 51200\n",
    "# 24 4096\n",
    "# 22 4096\n",
    "# 28 4096\n",
    "# 22 4096\n",
    "## for hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "c7d051c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = nn.Embedding(x_train_vector.size(0), 32).to(device)\n",
    "out = embedded(x_train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bf0d9a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([51200, 24, 32])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3b657aa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initHidden() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HICLIP~1\\AppData\\Local\\Temp/ipykernel_12716/1907610789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: initHidden() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "hidden = EncoderRNN.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "92d2d918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HICLIP~1\\AppData\\Local\\Temp/ipykernel_12716/1932107486.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hidden' is not defined"
     ]
    }
   ],
   "source": [
    "output, hidden = nn.GRU(out, hidden).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4e6a4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll need a unique index per word to use as the inputs and targets of the networks later. \n",
    "#To keep track of all this we will use a helper class called Lang which has word → index (word2index)\n",
    "#and index → word (index2word) dictionaries, as well as a count of each word word2count\n",
    "#which will be used to replace rare words later.\n",
    "\n",
    "# SOS_token = 0\n",
    "# EOS_token = 1\n",
    "\n",
    "\n",
    "# class Lang:\n",
    "#     def __init__(self, name):\n",
    "#         self.name = name\n",
    "#         self.characters2index = {}\n",
    "#         self.characters2count = {}\n",
    "#         self.index2characters = {0: \"SOS\", 1: \"EOS\"}\n",
    "#         self.n_characters = 2  # Count SOS and EOS\n",
    "\n",
    "#     def addWord(self, word):\n",
    "#         for character in list(word):\n",
    "#             self.addCharacter(character)\n",
    "\n",
    "#     def addCharacter(self, character):\n",
    "#         if character not in self.characters2index:\n",
    "#             self.characters2index[character] = self.n_characters\n",
    "#             self.characters2count[character] = 1\n",
    "#             self.index2characters[self.n_characters] = character\n",
    "#             self.n_characters += 1\n",
    "#         else:\n",
    "#             self.characters2count[character] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "819fd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_lang = Lang('eng')\n",
    "# output_lang = Lang('devanagari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "21ff666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair in zip(give_pair(train_data,0),give_pair(train_data,1)):  \n",
    "#     input_lang.addWord(pair[0])\n",
    "#     output_lang.addWord(pair[1])\n",
    "# print(\"Counted words:\")\n",
    "# print(input_lang.name, input_lang.n_characters)\n",
    "# print(output_lang.name, output_lang.n_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee476a6",
   "metadata": {},
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c9f6d",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "fadae557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    #input_size represents the dimensionality of the \n",
    "    #encoder's input space, indicating the number of possible input tokens or\n",
    "    #categories that the coder can generate.\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, cell_type):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell_type):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        if cell_type == 'gru':\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        if cell_type == 'lstm':\n",
    "            output, hidden = self.lstm(output, hidden)\n",
    "        if cell_type == 'rnn':\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    # This method is called at the beginning of each new input sequence\n",
    "    # to reset the hidden state.\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b06fdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden: This argument represents the initial hidden state of the RNN. It is expected to be a tensor of\n",
    "# shape (num_layers * num_directions, batch_size, hidden_size). Since we are dealing with a single-layer RNN, \n",
    "# the tensor shape is (1, 1, hidden_size). The hidden tensor is updated during the forward pass and passed as the \n",
    "# hidden state for the next time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7f8c2",
   "metadata": {},
   "source": [
    "### The Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "1bd26b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    #output_size represents the dimensionality of the \n",
    "    #decoder's output space, indicating the number of possible output tokens or\n",
    "    #categories that the decoder can generate.\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, cell_type):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, cell_type):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        if cell_type == 'gru':\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        if cell_type == 'lstm':\n",
    "            output, hidden = self.lstm(output, hidden)\n",
    "        if cell_type == 'rnn':\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6166ab88",
   "metadata": {},
   "source": [
    "### Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "88e45d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p, max_length, cell_type):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.rnn = nn.RNN(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        if cell_type == 'gru':\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        if cell_type == 'lstm':\n",
    "            output, hidden = self.lstm(output, hidden)\n",
    "        if cell_type == 'rnn':\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3f2b9963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bindhya'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790f254",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b412b1cb",
   "metadata": {},
   "source": [
    "“Teacher forcing” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability.\n",
    "max_length: The maximum length of the output sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1408fac5",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c3ae458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden, 'rnn')\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "#         for di in range(target_length):\n",
    "#             decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, 'rnn')\n",
    "#             loss += criterion(decoder_output, target_tensor[di])\n",
    "#             decoder_input = target_tensor[di]  # Teacher forcing\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, 'rnn')\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Set the current target token as the next decoder input\n",
    "\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, 'rnn')\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == 129:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "77c3cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "#     encoder_optimizer.zero_grad()\n",
    "#     decoder_optimizer.zero_grad()\n",
    "\n",
    "#     input_length = input_tensor.size(0)\n",
    "#     target_length = target_tensor.size(0)\n",
    "\n",
    "#     encoder_hidden = encoder.initHidden()\n",
    "#     loss = 0\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(\n",
    "#             input_tensor[ei], encoder_hidden,'rnn')\n",
    "\n",
    "#     decoder_input = torch.tensor([[SOS_token]])  # Start of sequence\n",
    "\n",
    "#     decoder_hidden = encoder_hidden\n",
    "\n",
    "#     for di in range(target_length):\n",
    "#         decoder_output, decoder_hidden = decoder(\n",
    "#             decoder_input, decoder_hidden, 'rnn')\n",
    "\n",
    "#         loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "#         decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "#     loss.backward()\n",
    "\n",
    "#     encoder_optimizer.step()\n",
    "#     decoder_optimizer.step()\n",
    "\n",
    "#     return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "3cb1614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "873db652",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(28, 32, 'rnn').to(device)\n",
    "decoder = DecoderRNN(32, 130, 'rnn').to(device)\n",
    "n_iters = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a069f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# def trainIters(input_tensor, target_tensor, encoder, decoder, n_iters, batch_size, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "#     import time\n",
    "#     import math\n",
    "#     start = time.time()\n",
    "#     plot_losses = []\n",
    "#     print_loss_total = 0  # Reset every print_every\n",
    "#     plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "#     encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     criterion = nn.NLLLoss()\n",
    "\n",
    "#     # Create data loader\n",
    "#     train_data = torch.utils.data.TensorDataset(input_tensor, target_tensor)\n",
    "#     train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     total_batches = math.ceil(len(train_data) / batch_size)\n",
    "\n",
    "#     for iter in range(1, n_iters + 1):\n",
    "#         for i, (input_batch, target_batch) in enumerate(train_loader, 1):\n",
    "#             input_tensor = input_batch.transpose(0, 1)  # Transpose to have batch dimension first\n",
    "#             target_tensor = target_batch.transpose(0, 1)  # Transpose to have batch dimension first\n",
    "\n",
    "#             loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "#             print_loss_total += loss\n",
    "#             plot_loss_total += loss\n",
    "\n",
    "#             if iter % print_every == 0:\n",
    "#                 print_loss_avg = print_loss_total / print_every\n",
    "#                 print_loss_total = 0\n",
    "#                 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "#                                              iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "#             if iter % plot_every == 0:\n",
    "#                 plot_loss_avg = plot_loss_total / plot_every\n",
    "#                 plot_losses.append(plot_loss_avg)\n",
    "#                 plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)\n",
    "\n",
    "# def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "#     encoder_optimizer.zero_grad()\n",
    "#     decoder_optimizer.zero_grad()\n",
    "\n",
    "#     input_length = input_tensor.size(0)\n",
    "#     target_length = target_tensor.size(0)\n",
    "\n",
    "#     encoder_hidden = encoder.initHidden()\n",
    "\n",
    "#     loss = 0\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden, 'rnn')\n",
    "\n",
    "#     decoder_input = torch.tensor([[SOS_token]])  # Start of sequence\n",
    "\n",
    "#     decoder_hidden = encoder_hidden\n",
    "\n",
    "#     for di in range(target_length):\n",
    "#         decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden,'rnn')\n",
    "\n",
    "#         loss += criterion(decoder_output, target_tensor[di])\n",
    "\n",
    "#         decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "#     loss.backward()\n",
    "\n",
    "#     encoder_optimizer.step()\n",
    "#     decoder_optimizer.step()\n",
    "\n",
    "#     return loss.item()\n",
    "\n",
    "# trainIters(x_train, y_train, encoder, decoder, n_iters, batch_size=64, print_every=1000, plot_every=100, learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b6216080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# def trainIters(x_train, y_train, encoder, decoder, n_iters, batch_size, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "#     import time\n",
    "#     import math\n",
    "#     start = time.time()\n",
    "#     plot_losses = []\n",
    "#     print_loss_total = 0  # Reset every print_every\n",
    "#     plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "#     encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "#     decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     criterion = nn.NLLLoss()\n",
    "\n",
    "#     # Convert data to tensors\n",
    "#     x_train = torch.tensor(x_train, dtype=torch.long)\n",
    "#     y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "#     # Create data loader\n",
    "#     train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "#     train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     total_batches = math.ceil(len(train_data) / batch_size)\n",
    "\n",
    "#     for iter in range(1, n_iters + 1):\n",
    "#         for i, (input_batch, target_batch) in enumerate(train_loader, 1):\n",
    "#             input_tensor = input_batch.transpose(0, 1)  # Transpose to have batch dimension first\n",
    "#             target_tensor = target_batch.transpose(0, 1)  # Transpose to have batch dimension first\n",
    "\n",
    "#             loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "#             print_loss_total += loss\n",
    "#             plot_loss_total += loss\n",
    "\n",
    "#             if iter % print_every == 0:\n",
    "#                 print_loss_avg = print_loss_total / print_every\n",
    "#                 print_loss_total = 0\n",
    "#                 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "#                                              iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "#             if iter % plot_every == 0:\n",
    "#                 plot_loss_avg = plot_loss_total / plot_every\n",
    "#                 plot_losses.append(plot_loss_avg)\n",
    "#                 plot_loss_total = 0\n",
    "\n",
    "#     showPlot(plot_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "dd577d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainIters(x_train, y_train, encoder, decoder, n_iters, batch_size=64,\n",
    "#            print_every=1000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "c2dc113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(x_train, y_train, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    import time\n",
    "    import math\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "#     training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "#         training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = x_train[iter % len(x_train)]\n",
    "        target_tensor = y_train[iter % len(y_train)]\n",
    "\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, 130)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "2f7a3db8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1) to match target batch_size (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HICLIP~1\\AppData\\Local\\Temp/ipykernel_12716/3072957357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainIters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\HICLIP~1\\AppData\\Local\\Temp/ipykernel_12716/2609724683.py\u001b[0m in \u001b[0;36mtrainIters\u001b[1;34m(x_train, y_train, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0m\u001b[0;32m     21\u001b[0m                      decoder, encoder_optimizer, decoder_optimizer, criterion, 130)\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\HICLIP~1\\AppData\\Local\\Temp/ipykernel_12716/3544623519.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rnn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Set the current target token as the next decoder input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2699\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2700\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2701\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (1) to match target batch_size (0)."
     ]
    }
   ],
   "source": [
    "trainIters(x_train, y_train, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_tensor=x_train_vector\n",
    "# target_tensor=y_train_vector\n",
    "# encoder\n",
    "# decoder\n",
    "# encoder_optimizer\n",
    "# decoder_optimizer\n",
    "# criterion\n",
    "# max_length\n",
    "# epochs =1\n",
    "# for i in range(epochs):\n",
    "#     train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
