{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f55d45",
   "metadata": {},
   "source": [
    "## CS6910 Assignment 3\n",
    "#### This code file contains all the classes and functions \n",
    "#### needed to train the Sequence to sequence model with attention mechansism \n",
    "#### I have mentioned the Reference sources that i have used to write the code in the README.me file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18abe3",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18f84d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239a5aa",
   "metadata": {},
   "source": [
    "## Argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using argparse, I have define the arguments and options that my program accepts,\n",
    "# and argparse will run the code, pass arguments from command line and \n",
    "# automatically generate help messages. I have given the defaults values for \n",
    "# all the arguments, so code can be run without passing any arguments.\n",
    "# lastly returning the arguments to be used in the running of the code.\n",
    "\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Stores all the hyperpamaters for the model.\")\n",
    "parser.add_argument(\"-wp\", \"--wandb_project\",default=\"cs6910_assignment 3 new\" ,type=str,\n",
    "                    help=\"Enter the Name of your Wandb Project\")\n",
    "parser.add_argument(\"-we\", \"--wandb_entity\", default=\"am22s020\",type=str,\n",
    "                    help=\"Wandb Entity used to track experiments in the Weights & Biases dashboard.\")\n",
    "parser.add_argument(\"-ws\", \"--wandb_sweep\", default=\"False\", type=bool,\n",
    "                    help=\"If you want to run wandb sweep then give True\")\n",
    "parser.add_argument(\"-e\", \"--epochs\",default=\"1\", type=int, choices=[1, 5, 10],\n",
    "                    help=\"Number of epochs to train neural network.\")\n",
    "parser.add_argument(\"-hs\", \"--hidden_size\",default=\"256\", type=int, help=\"no. of neurons in the hidden layer of the N/W\")\n",
    "parser.add_argument(\"-c\", \"--cell_type\",default=\"lstm\", type=str, choices=[\"lstm\", \"gru\", \"rnn\"])\n",
    "parser.add_argument(\"-nl\", \"--num_layers\",default=\"2\", type=int, \n",
    "                    choices=[2, 3, 4], help=\"number of recurrent layers\")\n",
    "parser.add_argument(\"-ems\", \"--embedding_size\", default=\"256\", type=int, choices=[64, 128, 256])\n",
    "parser.add_argument(\"-bd\", \"--bi_directional\", default=\"True\", type=bool)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "wandb_project = args.wandb_project\n",
    "wandb_entity = args.wandb_entity\n",
    "wandb_sweep = args.wandb_sweep\n",
    "num_epochs = args.epochs\n",
    "hidden_size = args.hidden_size\n",
    "cell_type = args.cell_type\n",
    "num_layers = args.num_layers\n",
    "embedding_size = args.embedding_size\n",
    "bi_directional = args.bi_directional\n",
    "\n",
    "print(\"wandb_project :\", wandb_project , \"wandb_entity: \", wandb_entity,\"wandb_sweep: \",wandb_sweep,\n",
    "      \"epochs: \",num_epochs,\"hidden_size: \",hidden_size, \"cell_type: \", cell_type,\n",
    "      \"num_layers: \",num_layers,\"embedding_size: \",embedding_size, \n",
    "      \"bi_directional: \", bi_directional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa839033",
   "metadata": {},
   "source": [
    "## Preparing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d84293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary():\n",
    "    \"\"\"\n",
    "    This class(Vocabulary), builds a character-level vocabulary for a given list of words.\n",
    "    It initializes the vocabulary with four special tokens (PAD, SOW, EOW, and UNK) and creates\n",
    "    two dictionaries (stoi and itos) to map characters to integers and vice versa.\n",
    "    Tokenizer: Tokenizes a given text into individual characters.\n",
    "    build_vocabulary(): Takes a list of words and adds each unique character \n",
    "    to the vocabulary, along with a unique integer ID.\n",
    "    numericalize(): Converts a given text into a list of integers, where each \n",
    "    integer corresponds to the ID of a character in the vocabulary.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.itos = {0:\"<PAD>\",1:\"<SOW>\",2:\"<EOW>\",3:\"<UNK>\"}\n",
    "        self.stoi = {\"<PAD>\":0,\"<SOW>\":1,\"<EOW>\":2,\"<UNK>\":3}\n",
    "        #self.freq_threshold = freq_threshold\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return [*text]\n",
    "    \n",
    "    def build_vocabulary(self, word_list):\n",
    "        char_list = []\n",
    "        idx = 4\n",
    "        \n",
    "        for word in word_list:\n",
    "            for char in self.tokenizer(word):\n",
    "                if char not in char_list:\n",
    "                    char_list.append(char)\n",
    "                    self.stoi[char] = idx\n",
    "                    self.itos[idx] = char\n",
    "                    idx+=1\n",
    "                    \n",
    "                    \n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        \n",
    "        return [self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text]\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a735130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class aksharantar(Dataset):\n",
    "    \"\"\"\n",
    "    This class used to process text data for a machine translation task.\n",
    "    root_dir: the root directory where the data is stored\n",
    "    out_lang: the target language for translation \n",
    "    dataset_type: either \"train\", \"test\", or \"val\" indicating which dataset is being used.\n",
    "    After loadinf data __init__() builds the vocabulary for each language by adding all unique characters in \n",
    "    the language's text data to the corresponding Vocabulary object.\n",
    "    The __getitem__() method takes an index and returns the numericalized form of the corresponding input \n",
    "    and output sentences.\n",
    "    It tokenizes each sentence into characters and adds special start-of-word (<SOW>) and end-of-word (<EOW>) \n",
    "    tokens to the beginning and end of the numericalized output sentence.\n",
    "    Finally, it returns PyTorch tensors of the numericalized input and output sentences.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, root_dir, out_lang, dataset_type): \n",
    "        \n",
    "        # Read file\n",
    "        self.file_name = out_lang + \"_\" + dataset_type + \".csv\"\n",
    "        self.file_dir = os.path.join(root_dir, out_lang, self.file_name)\n",
    "        self.df = pd.read_csv(self.file_dir, names = [\"latin\", \"hindi\"])\n",
    "        \n",
    "        # Get columns of input and output language\n",
    "        self.latin = self.df[\"latin\"]\n",
    "        self.hindi = self.df[\"hindi\"]\n",
    "        \n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab_eng = Vocabulary()\n",
    "        self.vocab_eng.build_vocabulary(self.latin.tolist())\n",
    "        \n",
    "        # Initialize vocabulary and build vocab\n",
    "        self.vocab_hin = Vocabulary()\n",
    "        self.vocab_hin.build_vocabulary(self.hindi.tolist())\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        latin = self.latin[index]\n",
    "        hindi = self.hindi[index]\n",
    "        \n",
    "        numericalized_hindi = [self.vocab_hin.stoi[\"<SOW>\"]]\n",
    "        numericalized_hindi += self.vocab_hin.numericalize(hindi)\n",
    "        numericalized_hindi.append(self.vocab_hin.stoi[\"<EOW>\"])\n",
    "        \n",
    "        numericalized_latin = [self.vocab_eng.stoi[\"<SOW>\"]]\n",
    "        numericalized_latin += self.vocab_eng.numericalize(latin)\n",
    "        numericalized_latin.append(self.vocab_eng.stoi[\"<EOW>\"])\n",
    "        \n",
    "        return torch.tensor(numericalized_latin), torch.tensor(numericalized_hindi) \n",
    "               \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693eddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    \"\"\"\n",
    "    This class is used to collate the data items into batches for DataLoader. \n",
    "    It takes two arguments, pad_idx_eng and pad_idx_hin, which are the index of the <PAD> token\n",
    "    in the English and Hindi vocabularies respectively.\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, pad_idx_eng, pad_idx_hin):\n",
    "        self.pad_idx_eng = pad_idx_eng\n",
    "        self.pad_idx_hin = pad_idx_hin\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        inputs = [item[0] for item in batch]\n",
    "        inputs = pad_sequence(inputs, batch_first=False, padding_value=self.pad_idx_eng)\n",
    "        \n",
    "        targets = [item[1] for item in batch]\n",
    "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx_hin)\n",
    "        \n",
    "        return inputs, targets\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad823864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(root_dir, out_lang, dataset_type, batch_size, pin_memory=True ):\n",
    "    \"\"\"\n",
    "    This class returns a PyTorch DataLoader object and a custom dataset object. \n",
    "    The DataLoader object loads the data in batches.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = aksharantar(root_dir, out_lang, dataset_type)\n",
    "    \n",
    "    pad_idx_eng = dataset.vocab_eng.stoi[\"<PAD>\"]\n",
    "    pad_idx_hin = dataset.vocab_hin.stoi[\"<PAD>\"]\n",
    "    \n",
    "    loader = DataLoader(dataset=dataset,batch_size=batch_size,\n",
    "                       pin_memory=pin_memory,\n",
    "                       collate_fn=MyCollate(pad_idx_eng=pad_idx_eng, pad_idx_hin=pad_idx_hin),\n",
    "                       shuffle=True)\n",
    "    return loader, dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dae4f",
   "metadata": {},
   "source": [
    "## Getting the model Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffacf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This code defines an Encoder class for a sequence-to-sequence model.\n",
    "    The class takes in an input size, embedding size, hidden size, \n",
    "    number of layers, dropout rate, cell type (GRU, LSTM, or RNN), \n",
    "    and whether the network is bidirectional. The forward method takes in \n",
    "    an input tensor x, applies dropout to its embedded representation, and \n",
    "    passes it through a GRU, LSTM, or RNN layer depending on the cell type specified. \n",
    "    The final hidden states of the layer(s) are returned.\n",
    "    \n",
    "    \"\"\"\n",
    "    #input_size represents the dimensionality of the \n",
    "    #encoder's input space, indicating the number of possible input tokens or\n",
    "    #categories that the coder can generate.\n",
    "    \n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, cell_type, bi_directional):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.dropout = nn.Dropout(p)\n",
    "            \n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout=p, bidirectional=bi_directional)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,bidirectional=bi_directional)\n",
    "        self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout=p,bidirectional=bi_directional)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x, shape=(seq_length, N)\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape = (seq_length, N,embedding_size )\n",
    "        \n",
    "        if self.cell_type == 'gru':\n",
    "            encoder_states, hidden = self.gru(embedding)\n",
    "            return encoder_states, hidden\n",
    "        \n",
    "        if self.cell_type == 'lstm':\n",
    "            encoder_states, (hidden, cell) = self.lstm(embedding)\n",
    "            return encoder_states, hidden, cell\n",
    "        \n",
    "        if self.cell_type == 'rnn':\n",
    "            encoder_states, hidden = self.rnn(embedding)\n",
    "            return encoder_states, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7d38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This code defines the Decoder class, which is responsible for decoding the encoded input sequence\n",
    "    and generating the target sequence. \n",
    "    The method first unsqueezes x to add a batch dimension and then applies dropout to the embedding layer. \n",
    "    It then passes the embedded input sequence through the decoder's RNN layer, \n",
    "    which can be either GRU, LSTM, or RNN.\n",
    "    Then passes the output through a linear layer to get the predictions, which are returned \n",
    "    along with the hidden and cell states.\n",
    "    Finally, the method squeezes the predictions tensor to remove the batch dimension before returning \n",
    "    the predictions and hidden/cell states.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers,\n",
    "                 p, cell_type, bi_directional ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.fc_hidden = nn.Linear(2*hidden_size, hidden_size)\n",
    "        \n",
    "        if bi_directional: # correct\n",
    "            self.energy = nn.Linear(hidden_size * 3, 1)\n",
    "        else:\n",
    "            self.energy = nn.Linear(hidden_size * 2, 1) \n",
    "            \n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        if bi_directional:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(input_size, embedding_size*2)\n",
    "        \n",
    "        if bi_directional:\n",
    "            self.gru = nn.GRU(hidden_size * 2 + embedding_size, hidden_size, num_layers, \n",
    "                              dropout=p,bidirectional=bi_directional )\n",
    "        else:\n",
    "            self.gru = nn.GRU(3*embedding_size, hidden_size, num_layers, dropout=p,bidirectional=bi_directional )\n",
    "            \n",
    "        if bi_directional: # correct\n",
    "            self.lstm = nn.LSTM(hidden_size * 2 + embedding_size, hidden_size,num_layers,\n",
    "                                dropout=p, bidirectional=bi_directional)\n",
    "        else:\n",
    "            self.lstm = nn.LSTM(3* embedding_size, hidden_size,num_layers, dropout=p, bidirectional=bi_directional)\n",
    "         \n",
    "        if bi_directional:\n",
    "            self.rnn = nn.RNN(hidden_size * 2 + embedding_size, hidden_size,num_layers,\n",
    "                              dropout=p, bidirectional=bi_directional)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(3*embedding_size, hidden_size,num_layers, dropout=p, bidirectional=bi_directional)\n",
    "            \n",
    "        if bi_directional: # correct\n",
    "            self.fc = nn.Linear(2*hidden_size, output_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, output_size)        \n",
    "        \n",
    "    def forward(self, x, encoder_states, hidden, cell):\n",
    "        # x, shape=(N) but we want (1, N)\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape = (1, N,embedding_size )\n",
    "        \n",
    "        sequence_length = encoder_states.shape[0]\n",
    "        hidden1 = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
    "        h_reshaped = hidden1.repeat(sequence_length, 1, 1)\n",
    "        \n",
    "        energy = self.relu(self.energy(torch.cat((h_reshaped, encoder_states), dim=2)))\n",
    "        \n",
    "        attention = self.softmax(energy)\n",
    "        # attention: (seq_length, N, 1)\n",
    "        \n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_states)\n",
    "\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "        # rnn_input: (1, N, hidden_size*2 + embedding_size)\n",
    "        \n",
    "        if self.cell_type == 'gru':\n",
    "            outputs, hidden = self.gru(rnn_input, hidden)\n",
    "            #shape of output (1,N,hidden_size)\n",
    "            \n",
    "        if self.cell_type == 'lstm':\n",
    "            outputs, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
    "            \n",
    "        if self.cell_type == 'rnn':\n",
    "            outputs, hidden = self.rnn(rnn_input, hidden)\n",
    "            \n",
    "        predictions = self.fc(outputs).squeeze(0)\n",
    "        # shape of predictions = (1, N, length_of_vocabs)\n",
    "        \n",
    "        \n",
    "        if self.cell_type == 'lstm':\n",
    "            return predictions, hidden, cell\n",
    "        else:\n",
    "            return predictions, hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d1d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    This class have functions which takes words as input and target words to find the \n",
    "    predictions using the model build in the forward function.\n",
    "    This function uses the encoder and decoder formed earlier.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, cell_type):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type = cell_type\n",
    "        \n",
    "    def forward(self, word_input, word_target, teacher_force_ratio=0.5):\n",
    "        \n",
    "        batch_size = word_input.shape[1]\n",
    "        target_length = word_target.shape[0]\n",
    "        \n",
    "        outputs = torch.zeros(target_length, batch_size, len(train_data.vocab_hin)).to(device)\n",
    "        \n",
    "        if self.cell_type == 'lstm':\n",
    "            encoder_states, hidden, cell = self.encoder(word_input)\n",
    "        else:\n",
    "            encoder_states, hidden = self.encoder(word_input)\n",
    "            \n",
    "        # grab start token\n",
    "        x= word_target[0]\n",
    "        \n",
    "        for t in range(1, target_length):\n",
    "            if self.cell_type == \"lstm\":\n",
    "                output, hidden, cell = self.decoder(x, encoder_states, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(x, encoder_states, hidden, 0)\n",
    "                \n",
    "            outputs[t] = output\n",
    "            \n",
    "            best_pred = output.argmax(1)\n",
    "            \n",
    "            x = word_target[t] if random.random() < teacher_force_ratio else best_pred\n",
    "            \n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f1a17f",
   "metadata": {},
   "source": [
    "## Functions to find accuracy and print and save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d51855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_list, cell_type, max_length=30):\n",
    "    \n",
    "    '''\n",
    "    The purpose of this function is to accept a list of characters in the input \n",
    "    language and then provide a list of characters in the output language.\n",
    "    cell_type: to use which among lstm, rnn or gru cell\n",
    "    max_length: The maximum length of latin input.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Making the indexes of the input according to the training data vocabulary\n",
    "    # Because the index2str dicts of train data and val/test datasets are diffent\n",
    "    \n",
    "    input_word = [train_data.vocab_eng.stoi[char] for char in input_list]\n",
    "    input_word = torch.LongTensor(input_word)\n",
    "\n",
    "    # Input word is of shape (seq_length) but we want it to be (seq_length, 1) where 1 represents batch size\n",
    "    input_word = input_word.view(input_word.shape[0],1).to(device)\n",
    "    \n",
    "    start_token_index = 1\n",
    "    end_token_index = 2\n",
    "   \n",
    "    # Encoder\n",
    "    with torch.no_grad():\n",
    "        if model.cell_type == \"lstm\":\n",
    "            encoder_states, hidden, cell = model.encoder(input_word)\n",
    "        else:\n",
    "            encoder_states, hidden = model.encoder(input_word)\n",
    "    \n",
    "    # Add start token to outputs\n",
    "    outputs = [start_token_index]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        prev_char = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if model.cell_type == \"lstm\":\n",
    "                output, hidden, cell = model.decoder(prev_char, encoder_states, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = model.decoder(prev_char, encoder_states, hidden, 0)\n",
    "            \n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model predicts it's the end of the sentence\n",
    "        if output.argmax(1).item() == end_token_index:\n",
    "            break\n",
    "    \n",
    "    # Convert outputs to character list\n",
    "    prediction = [train_data.vocab_hin.itos[index] for index in outputs]\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5a1d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataset, cell_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will comapre the prediction given by the predict function and the target output.\n",
    "    I will do word by word, so may take little more time.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initializing the count\n",
    "    correct_count = 0\n",
    "    # Number of data in our dataset\n",
    "    words_count = len(dataset)\n",
    "    \n",
    "    for i in range(words_count):\n",
    "        \n",
    "        char_input = [dataset.vocab_eng.itos[index] for index in dataset[i][0].tolist()]\n",
    "        prediction = predict(model, char_input, cell_type)\n",
    "        actual_word = [dataset.vocab_hin.itos[index] for index in dataset[i][1].tolist()]\n",
    "        if prediction == actual_word:\n",
    "            correct_count+=1\n",
    "            \n",
    "    return 100*(correct_count/words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc48a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  prediction_csv(model, dataset, cell_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function will create the csv file having 3 columns namely Input(words),\n",
    "    prediction and target. \n",
    "    model: Trained model whose accuracy to be seen for transliteration task.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initializing the count\n",
    "    correct_count = 0\n",
    "    # Number of data in our dataset\n",
    "    words_count = len(dataset)\n",
    "    # Initializing list to store lists, to save in csv file\n",
    "    list_of_words = []\n",
    "    \n",
    "    for i in range(words_count):\n",
    "        list1 = []\n",
    "        char_input = [dataset.vocab_eng.itos[index] for index in dataset[i][0].tolist()]\n",
    "        input_string = ''.join(char_input[1:len(char_input)-1])\n",
    "        list1.append(input_string)\n",
    "        prediction = predict(model, char_input, cell_type)\n",
    "        pred_string = ''.join(prediction[1:len(prediction)-1])\n",
    "        list1.append(pred_string)\n",
    "        actual_word = [dataset.vocab_hin.itos[index] for index in dataset[i][1].tolist()]\n",
    "        target_string = ''.join(actual_word[1:len(actual_word)-1])\n",
    "        list1.append(target_string)\n",
    "        list_of_words.append(list1)\n",
    "        if prediction == actual_word:\n",
    "            correct_count+=1\n",
    "    \n",
    "    # Creating the csv file in writing mode to write values stored in list_of_words\n",
    "    with open('predictions_attention.csv',mode='w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        header = [\"Inputs\", \"output\",\"Target\"]\n",
    "    \n",
    "        # Write header row\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for i in range(words_count):\n",
    "            writer.writerow(list_of_words[i])\n",
    "            \n",
    "    return 100*(correct_count/words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab39486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, learning_rate, batch_size, load_model, \n",
    "         input_size_encoder, input_size_decoder, output_size,\n",
    "         encoder_embedding_size, decoder_embedding_size,\n",
    "         hidden_size, num_layers, enc_dropout, de_dropout):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is created to train the Seq2Seq model manually(without wandb).\n",
    "    It takes the all the arguments needed for the encoder, decoder and Seq2seq model.\n",
    "    Using this function we can test our model on test dataset, just uncomment the relevant line \n",
    "    commented in the lower part of the code.\n",
    "    We can also generate prediction_vanilla csv file just by uncomment the \n",
    "    second last commented part of this code.\n",
    "    We can also print the prediction by uncommenting the last part\n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    # Importing the Encoder class\n",
    "    encoder_net = Encoder(input_size_encoder, encoder_embedding_size,\n",
    "                         hidden_size, num_layers, enc_dropout, cell_type,\n",
    "                          bi_directional).to(device)\n",
    "    \n",
    "    # Importing the Decoder class\n",
    "    decoder_net = Decoder(input_size_decoder, decoder_embedding_size,\n",
    "                         hidden_size, output_size, num_layers, dec_dropout, \n",
    "                          cell_type ,bi_directional).to(device)\n",
    "    \n",
    "    # Preparing the model\n",
    "    model = Seq2Seq(encoder_net, decoder_net, cell_type).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    pad_index = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "    \n",
    "    print(\"Training the model.....\")\n",
    "    if load_model:\n",
    "        load_checkpoint(torch.load('my_checkpoint.pth.ptar'),model, optimizer)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: ', epoch+1, '/', num_epochs)\n",
    "        \n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            \n",
    "            input_word = inputs.to(device)\n",
    "            target_word = targets.to(device)\n",
    "\n",
    "            output = model(input_word, target_word)\n",
    "            # output shape: (target_len, batch_size, output_vocab_size)\n",
    "            \n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target_word = target_word[1:].reshape(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target_word)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # To handle large gradients:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(\"Training Loss: \", loss.item())  \n",
    "        \n",
    "        model.eval()\n",
    "        print(\"finding the accuracy of the model.....\")\n",
    "        train_accu =  calculate_accuracy(model, train_data, cell_type)\n",
    "        valid_accu = calculate_accuracy(model, valid_data, cell_type)\n",
    "        model.train()\n",
    "\n",
    "        print(\"valid accuracy:\", valid_accu)\n",
    "        print(\"train accuracy:\", train_accu)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a21270c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Uploading\n",
    "# You can change the directory according to your data location\n",
    "# out_lang: Choose which output language you want transliteration.\n",
    "# 'hin':Hindi, 'urd':Urdu, 'tel':Telgu etc\n",
    "root_dir = r'C:\\Users\\HICLIPS-ASK\\aksharantar_sampled'\n",
    "out_lang = 'hin'\n",
    "batch_size = 64\n",
    "train_loader, train_data = get_loader(root_dir, out_lang, 'train', batch_size=batch_size, pin_memory=True )\n",
    "valid_loader, valid_data = get_loader(root_dir, out_lang, 'valid', batch_size=batch_size, pin_memory=True)\n",
    "test_loader, test_data = get_loader(root_dir, out_lang, 'test', batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "578df5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb_sweep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc6f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run manually Uncomment the above line 'wandb_sweep = False'\n",
    "if wandb_sweep == False:\n",
    "    ## Giving the argument values for manual training\n",
    "    num_epochs = 1\n",
    "    learning_rate = 0.001\n",
    "    load_model = False\n",
    "    input_size_encoder = len(train_data.vocab_eng)\n",
    "    input_size_decoder = len(train_data.vocab_hin)\n",
    "    output_size = len(train_data.vocab_hin)\n",
    "    encoder_embedding_size = 256\n",
    "    decoder_embedding_size = 256\n",
    "    hidden_size = 256\n",
    "    num_layers = 2\n",
    "    enc_dropout = 0.2\n",
    "    dec_dropout = 0.2\n",
    "    cell_type = 'lstm'\n",
    "    bi_directional = True\n",
    "\n",
    "    ## Training the model\n",
    "    train(num_epochs, learning_rate, batch_size, load_model, \n",
    "             input_size_encoder, input_size_decoder, output_size,\n",
    "             encoder_embedding_size, decoder_embedding_size,\n",
    "             hidden_size, num_layers, enc_dropout, dec_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25439295",
   "metadata": {},
   "source": [
    "## Training with Wandb_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca31d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"Assignment 3 with attention\"\n",
    "entity_name = \"am22s020\"\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04f58d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb():\n",
    "\n",
    "\n",
    "    config_defaults = {\"cell_type\": \"lstm\",\n",
    "                       \"num_layers\": 4,\n",
    "                       \"hidden_size\": 256,\n",
    "                       \"num_epochs\":10,\n",
    "                       \"dropout\": 0.2,\n",
    "                       \"embed_size\":256\n",
    "                      } \n",
    "\n",
    "    wandb.init(config=config_defaults, project=project_name, resume=False)\n",
    "    \n",
    "    config = wandb.config \n",
    "    \n",
    "    \n",
    "    learning_rate = 0.001\n",
    "    load_model = False\n",
    "    num_epochs = config.num_epochs\n",
    "    encoder_embedding_size = config.embed_size\n",
    "    decoder_embedding_size = config.embed_size\n",
    "    input_size_encoder = len(train_data.vocab_eng)\n",
    "    input_size_decoder = len(train_data.vocab_hin)\n",
    "    output_size = len(train_data.vocab_hin)\n",
    "    hidden_size = config.hidden_size\n",
    "    num_layers = config.num_layers\n",
    "    enc_dropout = config.dropout\n",
    "    dec_dropout = config.dropout\n",
    "    cell_type = config.cell_type\n",
    "    bi_directional = True\n",
    "\n",
    "    wandb.run.name  = \"cell_{}_nl_{}_hs_{}_e_{}_dr_{}_ems_{}\".format(cell_type,\n",
    "                                                                      num_layers,\n",
    "                                                                      hidden_size,\n",
    "                                                                      num_epochs,\n",
    "                                                                      enc_dropout,\n",
    "                                                                      encoder_embedding_size\n",
    "                                                                      )\n",
    "                                                                              \n",
    "                                                                                  \n",
    "  \n",
    "    print(wandb.run.name )\n",
    "    \n",
    "    encoder_net = Encoder(input_size_encoder, encoder_embedding_size,\n",
    "                         hidden_size, num_layers, enc_dropout, cell_type,\n",
    "                          bi_directional).to(device)\n",
    "\n",
    "    decoder_net = Decoder(input_size_decoder, decoder_embedding_size,\n",
    "                         hidden_size, output_size, num_layers, dec_dropout, \n",
    "                          cell_type ,bi_directional).to(device)\n",
    "\n",
    "    model = Seq2Seq(encoder_net, decoder_net, cell_type).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    pad_index = 0\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "    if load_model:\n",
    "        load_checkpoint(torch.load('my_checkpoint.pth.ptar'),model, optimizer)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch: ', epoch+1, '/', num_epochs)\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "\n",
    "            input_word = inputs.to(device)\n",
    "            target_word = targets.to(device)\n",
    "\n",
    "            output = model(input_word, target_word)\n",
    "            # output shape: (target_len, batch_size, output_vocab_size)\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            target_word = target_word[1:].reshape(-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, target_word)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # To handle large gradients:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Training Loss: \", loss.item())\n",
    "        \n",
    "        train_loss = loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        train_accu =  calculate_accuracy(model, train_data, cell_type)\n",
    "        valid_accu = calculate_accuracy(model, valid_data, cell_type)\n",
    "        model.train()\n",
    "\n",
    "        wandb.log({\"valid accuracy\": valid_accu, \"train accuracy\": train_accu,\n",
    "                    \"train loss\": train_loss, 'epoch': epoch+1})\n",
    "    \n",
    "    \n",
    "    wandb.run.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4468edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "\n",
    "        \"num_layers\": {\n",
    "            \"values\": [2, 3, 4]\n",
    "        },\n",
    "        \"hidden_size\": {\n",
    "            \"values\": [64, 128, 256]\n",
    "        },\n",
    "        \"cell_type\": {\n",
    "            \"values\": [\"rnn\", \"gru\", \"lstm\"]\n",
    "        },\n",
    "        \"num_epochs\":{\n",
    "            \"values\": [10, 20]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"values\": [0.2, 0.3, 0.5]\n",
    "        },\n",
    "        \"embed_size\":{\n",
    "            \"values\": [64, 128, 256]\n",
    "        },\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba3b95b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_sweep(project_name, entity_name):\n",
    "    '''\n",
    "    This function is used to run the wandb sweeps. \n",
    "    It takes in project name and entity name as input , and does not return any value.\n",
    "\n",
    "    '''\n",
    "    sweep_config={\n",
    "\n",
    "      \"method\": \"bayes\",\n",
    "      \"metric\": {\n",
    "          \"name\": \"valid_accu\", \n",
    "          \"goal\": \"maximize\"\n",
    "          },\n",
    "      \"parameters\":hyperparameters\n",
    "    }\n",
    "\n",
    "    sweep_id=wandb.sweep(sweep_config, project=project_name, entity=entity_name)\n",
    "    wandb.agent(sweep_id,train_with_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51724f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6imepp9f\n",
      "Sweep URL: https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gh6x48rw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mam22s020\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id 4f0nhrwd but id gh6x48rw is set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8777aa81b8074bf28f73b487b3e66e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_105404-gh6x48rw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/gh6x48rw' target=\"_blank\">misunderstood-sweep-1</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/gh6x48rw' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/gh6x48rw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_2_hs_128_e_20_dr_0.5_ems_64\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.4165784120559692\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.2466036081314087\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.327499508857727\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  0.8975704908370972\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  0.9984159469604492\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.9612013697624207\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.8561251759529114\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.7542168498039246\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.8064953088760376\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.9886434078216553\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  1.2049074172973633\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.6419394612312317\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.7579282522201538\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.8015043139457703\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.7942507266998291\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.9451488256454468\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.792537271976471\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.6033579111099243\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.5872355103492737\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.6419900059700012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52da33dadae740348217c68857e66611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train loss</td><td>█▇▇▄▄▄▃▂▃▄▆▁▂▃▃▄▃▁▁▁</td></tr><tr><td>valid accuracy</td><td>▁▅▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>36.08789</td></tr><tr><td>train loss</td><td>0.64199</td></tr><tr><td>valid accuracy</td><td>33.64258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-1</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/gh6x48rw' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/gh6x48rw</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_105404-gh6x48rw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zsgqymav with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2753757db411bb9c68b92e2d0fe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_122752-zsgqymav</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/zsgqymav' target=\"_blank\">ancient-sweep-2</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/zsgqymav' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/zsgqymav</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_lstm_nl_3_hs_64_e_10_dr_0.2_ems_128\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  1.74724280834198\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  1.2386507987976074\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  1.089850664138794\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  1.1127513647079468\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  1.0103193521499634\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  0.9446633458137512\n",
      "Epoch:  7 / 10\n",
      "Training Loss:  0.9373942613601685\n",
      "Epoch:  8 / 10\n",
      "Training Loss:  0.8420271873474121\n",
      "Epoch:  9 / 10\n",
      "Training Loss:  0.7148458957672119\n",
      "Epoch:  10 / 10\n",
      "Training Loss:  0.7802539467811584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9094f35a301f4ce0807cebdc8194b05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train loss</td><td>█▅▄▄▃▃▃▂▁▁</td></tr><tr><td>valid accuracy</td><td>▁▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train accuracy</td><td>29.87305</td></tr><tr><td>train loss</td><td>0.78025</td></tr><tr><td>valid accuracy</td><td>30.83496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-2</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/zsgqymav' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/zsgqymav</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_122752-zsgqymav\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qeojpxmu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3efd3dfad294327bdc6816463ee2839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_131555-qeojpxmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qeojpxmu' target=\"_blank\">apricot-sweep-3</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qeojpxmu' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qeojpxmu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_4_hs_128_e_20_dr_0.2_ems_256\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.131693720817566\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  0.7396837472915649\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  0.8153654932975769\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.2250787019729614\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  0.6277437806129456\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.6340178847312927\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.6432211995124817\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.7892532348632812\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.6260433197021484\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.6650139093399048\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.5047571659088135\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.501890242099762\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.6220911145210266\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.5953448414802551\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.5717355012893677\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.6496957540512085\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.48912838101387024\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.40190964937210083\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.5845766663551331\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.532211184501648\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▄▅▅▇▇▇▇▇█</td></tr><tr><td>train loss</td><td>▇▄▅█▃▃▃▄▃▃▂▂▃▃▂▃▂▁▃▂</td></tr><tr><td>valid accuracy</td><td>▁▆▇▆███▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>44.19922</td></tr><tr><td>train loss</td><td>0.53221</td></tr><tr><td>valid accuracy</td><td>31.54297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">apricot-sweep-3</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qeojpxmu' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qeojpxmu</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_131555-qeojpxmu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jpoxrrfg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17684cff0f6b4f3bb4667c9ee4f9d558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_145819-jpoxrrfg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/jpoxrrfg' target=\"_blank\">sleek-sweep-4</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/jpoxrrfg' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/jpoxrrfg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_3_hs_64_e_10_dr_0.3_ems_64\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  2.2788312435150146\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  1.6987394094467163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train loss</td><td>2.27883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-4</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/jpoxrrfg' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/jpoxrrfg</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_145819-jpoxrrfg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5yx48xcm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to auto resume run with id jpoxrrfg but id 5yx48xcm is set.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4021def1c140fcaa767c719434fa27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_150428-5yx48xcm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/5yx48xcm' target=\"_blank\">logical-sweep-5</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/5yx48xcm' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/5yx48xcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_3_hs_256_e_10_dr_0.2_ems_256\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  0.8902482986450195\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  0.6429905295372009\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  0.5765307545661926\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  0.6747865080833435\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  0.682616651058197\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  0.5456714034080505\n",
      "Epoch:  7 / 10\n",
      "Training Loss:  0.6132667064666748\n",
      "Epoch:  8 / 10\n",
      "Training Loss:  0.4423506259918213\n",
      "Epoch:  9 / 10\n",
      "Training Loss:  0.4361552298069\n",
      "Epoch:  10 / 10\n",
      "Training Loss:  0.3670375943183899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bc177b19b646679f525c9a3a16d9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train accuracy</td><td>▁▅▆▇█</td></tr><tr><td>train loss</td><td>█▅▄▅▅▃▄▂▂▁</td></tr><tr><td>valid accuracy</td><td>▁▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train accuracy</td><td>46.83203</td></tr><tr><td>train loss</td><td>0.36704</td></tr><tr><td>valid accuracy</td><td>35.00977</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-5</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/5yx48xcm' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/5yx48xcm</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_150428-5yx48xcm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dlyprlmt with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e3c6198e4a4e78922a9727af15c8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_160131-dlyprlmt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/dlyprlmt' target=\"_blank\">distinctive-sweep-6</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/dlyprlmt' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/dlyprlmt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_lstm_nl_3_hs_128_e_20_dr_0.5_ems_128\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.584213137626648\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.366572380065918\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.0190939903259277\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  0.9300316572189331\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  0.9060571193695068\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.7805853486061096\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.6091936230659485\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.7792050838470459\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.6729950308799744\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.7896996736526489\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.5015790462493896\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.8972135186195374\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.6439371109008789\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.6449766755104065\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.6032648682594299\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.48681697249412537\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.7367228269577026\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.5495006442070007\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.5323366522789001\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.3847866356372833\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57548b2045624b578ed566e3f4fca53e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train loss</td><td>█▇▅▄▄▃▂▃▃▃▂▄▃▃▂▂▃▂▂▁</td></tr><tr><td>valid accuracy</td><td>▁▄▅▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>45.79297</td></tr><tr><td>train loss</td><td>0.38479</td></tr><tr><td>valid accuracy</td><td>37.89062</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-6</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/dlyprlmt' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/dlyprlmt</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_160131-dlyprlmt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xd1bqqnr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6849cb5a82954f89be1d03504c3aa733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_174020-xd1bqqnr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/xd1bqqnr' target=\"_blank\">absurd-sweep-7</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/xd1bqqnr' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/xd1bqqnr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_lstm_nl_4_hs_256_e_10_dr_0.3_ems_64\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  1.4884495735168457\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  0.728722333908081\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  0.6766051054000854\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  0.6131076216697693\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  0.39085397124290466\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  0.5453477501869202\n",
      "Epoch:  7 / 10\n",
      "Training Loss:  0.4374116361141205\n",
      "Epoch:  8 / 10\n",
      "Training Loss:  0.545535147190094\n",
      "Epoch:  9 / 10\n",
      "Training Loss:  0.3848966658115387\n",
      "Epoch:  10 / 10\n",
      "Training Loss:  0.563019871711731\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train accuracy</td><td>▁▄▅▇█</td></tr><tr><td>train loss</td><td>█▃▃▂▁▂▁▂▁▂</td></tr><tr><td>valid accuracy</td><td>▁▅▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train accuracy</td><td>58.18945</td></tr><tr><td>train loss</td><td>0.56302</td></tr><tr><td>valid accuracy</td><td>41.40625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">absurd-sweep-7</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/xd1bqqnr' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/xd1bqqnr</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_174020-xd1bqqnr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kdu2vnf2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3631af700043579012725269671611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_184232-kdu2vnf2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/kdu2vnf2' target=\"_blank\">fanciful-sweep-8</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/kdu2vnf2' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/kdu2vnf2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_4_hs_256_e_20_dr_0.2_ems_128\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.3642313480377197\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.2878751754760742\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.0652996301651\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.0087907314300537\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  1.0444343090057373\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.9274753332138062\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  1.1034103631973267\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  1.286133885383606\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.9175023436546326\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.943825900554657\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.8577011227607727\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.9621949195861816\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  1.066468596458435\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.6589992642402649\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.9069973826408386\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.915599524974823\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.8813110589981079\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.7655790448188782\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  1.2116597890853882\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.9876663088798523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d97c88803a46ca84323d4e59fc5513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▂▇▇▇█▇██▆</td></tr><tr><td>train loss</td><td>█▇▅▄▅▄▅▇▄▄▃▄▅▁▃▄▃▂▆▄</td></tr><tr><td>valid accuracy</td><td>▁▂▇▆▆▇▆██▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>7.30859</td></tr><tr><td>train loss</td><td>0.98767</td></tr><tr><td>valid accuracy</td><td>8.59375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fanciful-sweep-8</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/kdu2vnf2' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/kdu2vnf2</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_184232-kdu2vnf2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qg3khhqc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dce0fdcc9c943dd89e9b1a739a600a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333266395, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_202427-qg3khhqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qg3khhqc' target=\"_blank\">grateful-sweep-9</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qg3khhqc' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qg3khhqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_lstm_nl_3_hs_128_e_20_dr_0.2_ems_64\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.2838928699493408\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.0000604391098022\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  0.8304522037506104\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  0.7251396179199219\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  0.7191965579986572\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.7313385009765625\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.562213659286499\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.4478086531162262\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.4061241149902344\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.6966181993484497\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.48672470450401306\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.4706825613975525\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.5229274034500122\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.38754552602767944\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.45503130555152893\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.4202267825603485\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.39057812094688416\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.3519270718097687\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.5190706253051758\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.5111334323883057\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbc824367da4cbfa8f42ba756435469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>train loss</td><td>█▆▅▄▄▄▃▂▁▄▂▂▂▁▂▂▁▁▂▂</td></tr><tr><td>valid accuracy</td><td>▁▅▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>62.2168</td></tr><tr><td>train loss</td><td>0.51113</td></tr><tr><td>valid accuracy</td><td>38.40332</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">grateful-sweep-9</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qg3khhqc' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/qg3khhqc</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_202427-qg3khhqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pw42aw9r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d96f4a15e194fd0b2d011ae9488e98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_220354-pw42aw9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pw42aw9r' target=\"_blank\">ethereal-sweep-10</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pw42aw9r' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pw42aw9r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_2_hs_64_e_10_dr_0.3_ems_256\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  1.9965745210647583\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  1.6847649812698364\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  1.5153617858886719\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  1.3774102926254272\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  1.5302456617355347\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  1.3955045938491821\n",
      "Epoch:  7 / 10\n",
      "Training Loss:  1.425681710243225\n",
      "Epoch:  8 / 10\n",
      "Training Loss:  1.3953337669372559\n",
      "Epoch:  9 / 10\n",
      "Training Loss:  1.128304362297058\n",
      "Epoch:  10 / 10\n",
      "Training Loss:  1.377143144607544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e89da8cdaf34493a56cb71316428b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train accuracy</td><td>▁▅▅▆█</td></tr><tr><td>train loss</td><td>█▅▄▃▄▃▃▃▁▃</td></tr><tr><td>valid accuracy</td><td>▁▆▆▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train accuracy</td><td>5.75</td></tr><tr><td>train loss</td><td>1.37714</td></tr><tr><td>valid accuracy</td><td>8.1543</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-10</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pw42aw9r' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pw42aw9r</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_220354-pw42aw9r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bpmldnyd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0977072015e46d48764e00ad3bf98af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230510_224921-bpmldnyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/bpmldnyd' target=\"_blank\">proud-sweep-11</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/bpmldnyd' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/bpmldnyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_3_hs_64_e_20_dr_0.2_ems_128\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.762741208076477\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.3755539655685425\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.1074259281158447\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.3761682510375977\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  1.3881056308746338\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  1.1670186519622803\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  1.1120853424072266\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  1.1046708822250366\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  1.1318095922470093\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  1.0630854368209839\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  1.057728886604309\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  1.0657644271850586\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.8444045186042786\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  1.0681583881378174\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  1.0240377187728882\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  1.0087336301803589\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  1.128905177116394\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  1.1534079313278198\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  1.065372109413147\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  1.0888338088989258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▃▄▅▆▆▇▇▇█</td></tr><tr><td>train loss</td><td>█▅▃▅▅▃▃▃▃▃▃▃▁▃▂▂▃▃▃▃</td></tr><tr><td>valid accuracy</td><td>▁▄▅▆▇▆▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>14.18164</td></tr><tr><td>train loss</td><td>1.08883</td></tr><tr><td>valid accuracy</td><td>17.04102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-11</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/bpmldnyd' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/bpmldnyd</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_224921-bpmldnyd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 925yk244 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858281481696424499dce6fe2ae64114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_002318-925yk244</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/925yk244' target=\"_blank\">fine-sweep-12</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/925yk244' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/925yk244</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_4_hs_128_e_10_dr_0.2_ems_256\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  1.128707766532898\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  0.8593323826789856\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  1.2122695446014404\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  0.9451954960823059\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  0.8347623348236084\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  0.8045775890350342\n",
      "Epoch:  7 / 10\n",
      "Training Loss:  0.6234214305877686\n",
      "Epoch:  8 / 10\n",
      "Training Loss:  0.511805534362793\n",
      "Epoch:  9 / 10\n",
      "Training Loss:  0.47723713517189026\n",
      "Epoch:  10 / 10\n",
      "Training Loss:  0.6181269288063049\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623200beaace45f18b84500b17f7f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train accuracy</td><td>▁▄▆▇█</td></tr><tr><td>train loss</td><td>▇▅█▅▄▄▂▁▁▂</td></tr><tr><td>valid accuracy</td><td>▁▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train accuracy</td><td>41.7168</td></tr><tr><td>train loss</td><td>0.61813</td></tr><tr><td>valid accuracy</td><td>32.95898</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-12</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/925yk244' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/925yk244</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230511_002318-925yk244\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x55k1cwc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ff28b9a69c4b63a3e636f491fc2dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_011429-x55k1cwc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/x55k1cwc' target=\"_blank\">astral-sweep-13</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/x55k1cwc' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/x55k1cwc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_3_hs_64_e_20_dr_0.2_ems_64\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.9479812383651733\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.6802910566329956\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.4481703042984009\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.3073465824127197\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  1.2452242374420166\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  1.2877197265625\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  1.2480745315551758\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  1.1411949396133423\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  1.1986076831817627\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  1.0641812086105347\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.9455357789993286\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  1.1273552179336548\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  1.0642919540405273\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.9417949318885803\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  1.0613768100738525\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  1.3470232486724854\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  1.0244343280792236\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.9074632525444031\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  1.0613924264907837\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.9817227721214294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▃▃▄▅▅▆▆▇█</td></tr><tr><td>train loss</td><td>█▆▅▄▃▄▃▃▃▂▁▂▂▁▂▄▂▁▂▁</td></tr><tr><td>valid accuracy</td><td>▁▄▄▄▅▆▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>16.30469</td></tr><tr><td>train loss</td><td>0.98172</td></tr><tr><td>valid accuracy</td><td>18.72559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-13</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/x55k1cwc' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/x55k1cwc</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230511_011429-x55k1cwc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7008ngem with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9faed34bad747c68d8206ad3d199df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333266395, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_024642-7008ngem</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/7008ngem' target=\"_blank\">fancy-sweep-14</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/7008ngem' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/7008ngem</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_3_hs_256_e_20_dr_0.5_ems_256\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.042359471321106\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.3073780536651611\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  0.793432354927063\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  0.8519611358642578\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  0.9663528800010681\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.8350262641906738\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.821759045124054\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.7729745507240295\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.8288685083389282\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  1.0298336744308472\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  1.0461642742156982\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.7668841481208801\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.9732661247253418\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  0.8840385675430298\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.8165715336799622\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.7950144410133362\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.6820006966590881\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  0.8555582761764526\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.6922104954719543\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.667971670627594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0837c025ffd5453f8b97f78c5793a815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▅▆▇▇█▇██▇</td></tr><tr><td>train loss</td><td>▅█▂▃▄▃▃▂▃▅▅▂▄▃▃▂▁▃▁▁</td></tr><tr><td>valid accuracy</td><td>▁▅▇▇▇█▆█▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>31.95117</td></tr><tr><td>train loss</td><td>0.66797</td></tr><tr><td>valid accuracy</td><td>31.83594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-sweep-14</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/7008ngem' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/7008ngem</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230511_024642-7008ngem\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6l1s2ibn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b96e26e2bc45a08151cd5ee95fcfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333145128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_043722-6l1s2ibn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/6l1s2ibn' target=\"_blank\">sparkling-sweep-15</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/6l1s2ibn' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/6l1s2ibn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_3_hs_64_e_20_dr_0.3_ems_256\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  2.1629936695098877\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.9090267419815063\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.583527684211731\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.4388577938079834\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  1.5759265422821045\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  1.4720187187194824\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  1.425864338874817\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  1.5961552858352661\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  1.3534411191940308\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  1.434489369392395\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  1.1694105863571167\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  1.2960999011993408\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  1.7680671215057373\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  1.1792243719100952\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  1.3230642080307007\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  1.110196828842163\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  1.2973885536193848\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  1.2906779050827026\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  1.4375064373016357\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  1.1765271425247192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45eb451648af450d8cca10ea75d387b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▂▃▄▄▅▆▆▇█</td></tr><tr><td>train loss</td><td>█▆▄▃▄▃▃▄▃▃▁▂▅▁▂▁▂▂▃▁</td></tr><tr><td>valid accuracy</td><td>▁▃▃▅▄▅▆▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>8.4043</td></tr><tr><td>train loss</td><td>1.17653</td></tr><tr><td>valid accuracy</td><td>11.40137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-15</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/6l1s2ibn' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/6l1s2ibn</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230511_043722-6l1s2ibn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pscxszu9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164d8bf62a9f438f80d3573468ba225e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_061212-pscxszu9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pscxszu9' target=\"_blank\">radiant-sweep-16</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pscxszu9' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pscxszu9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_gru_nl_4_hs_128_e_20_dr_0.5_ems_128\n",
      "Epoch:  1 / 20\n",
      "Training Loss:  1.6790268421173096\n",
      "Epoch:  2 / 20\n",
      "Training Loss:  1.2062088251113892\n",
      "Epoch:  3 / 20\n",
      "Training Loss:  1.4261326789855957\n",
      "Epoch:  4 / 20\n",
      "Training Loss:  1.0372810363769531\n",
      "Epoch:  5 / 20\n",
      "Training Loss:  1.0783706903457642\n",
      "Epoch:  6 / 20\n",
      "Training Loss:  0.801123321056366\n",
      "Epoch:  7 / 20\n",
      "Training Loss:  0.746178150177002\n",
      "Epoch:  8 / 20\n",
      "Training Loss:  0.8284363150596619\n",
      "Epoch:  9 / 20\n",
      "Training Loss:  0.9789810180664062\n",
      "Epoch:  10 / 20\n",
      "Training Loss:  0.992134153842926\n",
      "Epoch:  11 / 20\n",
      "Training Loss:  0.9993125796318054\n",
      "Epoch:  12 / 20\n",
      "Training Loss:  0.8070383071899414\n",
      "Epoch:  13 / 20\n",
      "Training Loss:  0.8044712543487549\n",
      "Epoch:  14 / 20\n",
      "Training Loss:  1.0868769884109497\n",
      "Epoch:  15 / 20\n",
      "Training Loss:  0.8012816309928894\n",
      "Epoch:  16 / 20\n",
      "Training Loss:  0.6489248275756836\n",
      "Epoch:  17 / 20\n",
      "Training Loss:  0.844541609287262\n",
      "Epoch:  18 / 20\n",
      "Training Loss:  1.019227385520935\n",
      "Epoch:  19 / 20\n",
      "Training Loss:  0.9667220115661621\n",
      "Epoch:  20 / 20\n",
      "Training Loss:  0.8941254615783691\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train accuracy</td><td>▁▄▆▆▇▇▇██▇</td></tr><tr><td>train loss</td><td>█▅▆▄▄▂▂▂▃▃▃▂▂▄▂▁▂▄▃▃</td></tr><tr><td>valid accuracy</td><td>▁▄▇▇▇▇██▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>train accuracy</td><td>22.3125</td></tr><tr><td>train loss</td><td>0.89413</td></tr><tr><td>valid accuracy</td><td>21.65527</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-sweep-16</strong> at: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pscxszu9' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/pscxszu9</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230511_061212-pscxszu9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sx1c6d7s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\HICLIPS-ASK\\wandb\\run-20230511_075145-sx1c6d7s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/sx1c6d7s' target=\"_blank\">solar-sweep-17</a></strong> to <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/sweeps/6imepp9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/sx1c6d7s' target=\"_blank\">https://wandb.ai/am22s020/Assignment%203%20with%20attention/runs/sx1c6d7s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_rnn_nl_3_hs_256_e_10_dr_0.2_ems_128\n",
      "Epoch:  1 / 10\n",
      "Training Loss:  1.2345741987228394\n",
      "Epoch:  2 / 10\n",
      "Training Loss:  1.2163000106811523\n",
      "Epoch:  3 / 10\n",
      "Training Loss:  0.9711766242980957\n",
      "Epoch:  4 / 10\n",
      "Training Loss:  1.2107219696044922\n",
      "Epoch:  5 / 10\n",
      "Training Loss:  0.813028872013092\n",
      "Epoch:  6 / 10\n",
      "Training Loss:  1.3652628660202026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if wandb_sweep == True:\n",
    "    wandb_sweep(project_name, entity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b95bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
